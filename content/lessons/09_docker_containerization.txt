Docker and Containerization: Modern Application Deployment

Docker is a platform for developing, shipping, and running applications in containers. Containers package an application with all its dependencies, ensuring it runs consistently across different computing environments. This has revolutionized software development and deployment, becoming an essential skill for modern developers.

What is Containerization?

Traditional Deployment Problems:
- "It works on my machine" syndrome
- Different OS, libraries, or configurations between dev/staging/production
- Dependency conflicts
- Difficult to replicate environments
- Complex deployment procedures

Containerization Solution:
Containers package:
- Application code
- Runtime environment (Python, Node, etc.)
- System libraries
- Configuration files
- Dependencies

Result: Application runs identically everywhere

Containers vs Virtual Machines:

Virtual Machines:
- Include full OS
- Larger size (GBs)
- Slower startup (minutes)
- More resource intensive
- Strong isolation

Containers:
- Share host OS kernel
- Smaller size (MBs)
- Fast startup (seconds)
- Lightweight
- Good isolation

Use cases: Containers are ideal for microservices, while VMs are better for running different operating systems or when you need stronger isolation.

Core Docker Concepts:

1. Image
A read-only template for creating containers:
- Built from a Dockerfile
- Contains application and dependencies
- Can be versioned and shared
- Stored in registries (Docker Hub, etc.)

Think of it as: A snapshot or blueprint

2. Container
A running instance of an image:
- Isolated process
- Has its own filesystem, networking, and process space
- Can be started, stopped, moved, deleted
- Ephemeral by default (data lost when removed)

Think of it as: A running application

3. Dockerfile
A text file with instructions to build an image:
- Specifies base image
- Defines how to install dependencies
- Copies application files
- Specifies startup command

4. Registry
Storage and distribution system for images:
- Docker Hub (public registry)
- Private registries (AWS ECR, Google Container Registry, etc.)
- Share and version images

5. Volume
Persistent data storage:
- Data survives container deletion
- Shared between containers
- Managed by Docker

6. Network
Allows containers to communicate:
- Bridge network (default)
- Host network
- Custom networks
- Service discovery

Creating a Dockerfile:

Basic Structure:
```dockerfile
# Base image
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Copy dependency file
COPY requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose port
EXPOSE 8000

# Command to run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

Dockerfile Instructions Explained:

FROM: Base image
- Specifies starting point
- Common bases: python:3.11, node:18, ubuntu:22.04
- Use slim/alpine variants for smaller images

WORKDIR: Set working directory
- All subsequent commands run in this directory
- Creates directory if it doesn't exist

COPY: Copy files from host to container
- COPY src dest
- Can copy individual files or directories
- Respects .dockerignore

ADD: Similar to COPY but with extra features
- Can extract archives
- Can fetch from URLs
- Generally prefer COPY for clarity

RUN: Execute commands during build
- Installs dependencies
- Compiles code
- Creates files/directories
- Each RUN creates a new layer

ENV: Set environment variables
- ENV KEY=value
- Available to all subsequent instructions
- Available when container runs

EXPOSE: Document which ports the app uses
- Doesn't actually publish ports
- Documentation for users
- Used by docker-compose

CMD: Default command when container starts
- Only one CMD instruction
- Can be overridden at runtime
- Example: CMD ["python", "app.py"]

ENTRYPOINT: Configures container as executable
- More rigid than CMD
- CMD becomes arguments to ENTRYPOINT
- Example: ENTRYPOINT ["python", "app.py"]

Best Practices for Dockerfiles:

1. Use specific base image versions
Bad: FROM python
Good: FROM python:3.11-slim

2. Minimize layers
Bad:
```dockerfile
RUN apt-get update
RUN apt-get install -y package1
RUN apt-get install -y package2
```

Good:
```dockerfile
RUN apt-get update && apt-get install -y \
    package1 \
    package2 \
    && rm -rf /var/lib/apt/lists/*
```

3. Order instructions by change frequency
- Put rarely changing instructions first
- Put frequently changing instructions last
- Leverages Docker's layer caching

Example:
```dockerfile
FROM python:3.11-slim
WORKDIR /app

# Dependencies change rarely
COPY requirements.txt .
RUN pip install -r requirements.txt

# Code changes frequently
COPY . .

CMD ["python", "app.py"]
```

4. Use .dockerignore
Exclude unnecessary files:
```
__pycache__/
*.pyc
.env
.git/
venv/
*.md
.DS_Store
```

5. Multi-stage builds
Reduce final image size:
```dockerfile
# Build stage
FROM python:3.11 AS builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --user -r requirements.txt

# Runtime stage
FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /root/.local /root/.local
COPY . .
ENV PATH=/root/.local/bin:$PATH
CMD ["python", "app.py"]
```

6. Run as non-root user
Security best practice:
```dockerfile
RUN useradd -m appuser
USER appuser
```

Docker Commands:

Build Image:
```bash
docker build -t myapp:latest .
docker build -t myapp:v1.0 -f Dockerfile.prod .
```

Run Container:
```bash
docker run myapp
docker run -d -p 8000:8000 myapp  # Detached, port mapping
docker run -e API_KEY=secret myapp  # Environment variable
docker run -v $(pwd):/app myapp     # Volume mount
```

List Containers:
```bash
docker ps           # Running containers
docker ps -a        # All containers
```

Stop/Start/Remove:
```bash
docker stop <container_id>
docker start <container_id>
docker rm <container_id>
```

Images:
```bash
docker images                 # List images
docker rmi <image_id>        # Remove image
docker pull ubuntu:22.04     # Download image
docker push myuser/myapp     # Upload to registry
```

Logs and Debugging:
```bash
docker logs <container_id>
docker logs -f <container_id>     # Follow logs
docker exec -it <container_id> bash  # Enter container
```

Docker Compose:

Manage multi-container applications with a single file.

docker-compose.yml Example:
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://db:5432/mydb
    depends_on:
      - db
    volumes:
      - ./data:/app/data

  db:
    image: postgres:15
    environment:
      - POSTGRES_PASSWORD=secret
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

Docker Compose Commands:
```bash
docker-compose up              # Start all services
docker-compose up -d           # Start in background
docker-compose down            # Stop and remove containers
docker-compose logs -f api     # View logs for api service
docker-compose exec api bash   # Execute command in container
docker-compose build           # Rebuild images
```

Networking in Docker Compose:

Containers in the same compose file can reach each other by service name:
```python
# In api container, connect to database:
DATABASE_URL = "postgresql://db:5432/mydb"
# "db" is the service name
```

Docker for AI/ML Applications:

Example Dockerfile for FastAPI + LangChain:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/ || exit 1

# Run application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

docker-compose.yml for RAG Application:
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./sample_data:/app/sample_data:ro
    depends_on:
      - redis

  frontend:
    build: ./frontend
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
    depends_on:
      - api

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

Environment Variable Management:

.env file:
```
OPENAI_API_KEY=sk-...
DATABASE_URL=postgresql://localhost/db
DEBUG=true
```

Reference in docker-compose:
```yaml
services:
  app:
    env_file:
      - .env
    # Or explicitly:
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
```

Security Best Practices:

1. Don't include secrets in images
- Use environment variables
- Use Docker secrets (Swarm)
- Use secret management tools

2. Use official base images
- From trusted sources
- Regularly updated
- Scan for vulnerabilities

3. Keep images up to date
- Update base images
- Update dependencies
- Scan with docker scan

4. Minimize image size
- Fewer dependencies = smaller attack surface
- Use alpine/slim variants
- Multi-stage builds

5. Run as non-root
- Create and use dedicated user
- Limit permissions

Production Considerations:

1. Image Optimization
- Multi-stage builds
- Minimal base images
- Layer caching

2. Logging
- Log to stdout/stderr
- Use log drivers
- Centralized logging

3. Monitoring
- Health checks
- Resource limits
- Metrics collection

4. Orchestration
- Kubernetes for large scale
- Docker Swarm for simpler needs
- Cloud services (ECS, Cloud Run)

5. CI/CD Integration
- Automated builds
- Image scanning
- Automated deployment

Docker has become essential in modern software development. For AI/ML applications, it ensures consistency across development, testing, and production environments, making deployment significantly more reliable and reproducible.
